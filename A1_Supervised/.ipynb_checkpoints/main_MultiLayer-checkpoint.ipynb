{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils import plotCase, loadDataSet, selectTrainingSamples, calcConfusionMatrix, calcAccuracy, plotResultDots, plotResultsOCR\n",
    "from classifiers import trainMultiLayer, runMultiLayer\n",
    "\n",
    "plt.rcParams['figure.facecolor']='white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script will help you test your single layer neural network code\n",
    "# Select which data to use:\n",
    "\n",
    "# 1 = dot cloud 1\n",
    "# 2 = dot cloud 2\n",
    "# 3 = dot cloud 3\n",
    "# 4 = OCR data\n",
    "\n",
    "dataSetNr = 1; # Change this to load new data\n",
    "\n",
    "# X - Data samples\n",
    "# D - Desired output from classifier for each sample\n",
    "# L - Labels for each sample\n",
    "X, D, L = loadDataSet(dataSetNr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset of the training samples\n",
    "numBins = 2                        # Number of bins you want to divide your data into\n",
    "numSamplesPerLabelPerBin = np.inf  # Number of samples per label per bin, set to inf for max number (total number is numLabels*numSamplesPerBin)\n",
    "selectAtRandom = True              # true = select samples at random, false = select the first features\n",
    "\n",
    "# Split data into bins based on the settings above.\n",
    "# The outputs are lists of length numBins, where each item is a data array. Try printing for example XBins[0].shape.\n",
    "XBins, DBins, LBins = selectTrainingSamples(X, D, L, numSamplesPerLabelPerBin, numBins, selectAtRandom)\n",
    "\n",
    "# To extract a single bin from them use e.g.:\n",
    "# XBin0 = XBins[0]\n",
    "# Or to combine several bins into one matrix (good for cross validataion), use the numpy function concatenate:\n",
    "# XBinComb = np.concatenate(XBins[0:4])\n",
    "# This example combines 4 bins, nr 0 to 3.\n",
    "\n",
    "# Add your own code to setup data for training and test here\n",
    "XTrain = ...\n",
    "DTrain = ...\n",
    "LTrain = ...\n",
    "XTest  = ...\n",
    "DTest  = ...\n",
    "LTest  = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the X Matrices so that a bias is added\n",
    "# Note that the bias must be the last feature for the plot code to work\n",
    "\n",
    "# The training data\n",
    "XTrain = ...\n",
    "\n",
    "# The test data\n",
    "XTest = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your multi layer network\n",
    "# Note: You need to modify trainMultiLayer() and runMultiLayer() in classifiers.py in order to train the network\n",
    "\n",
    "numHidden = 7          # Change this, number of hidden neurons\n",
    "numIterations = 800    # Change this, number of iterations (epochs)\n",
    "learningRate  = 0.001  # Change this, your learning rate\n",
    "W0 = 0                 # Initialize your weight matrix W\n",
    "V0 = 0                 # Initialize your weight matrix V\n",
    "\n",
    "# Run training loop\n",
    "W, V, ErrTrain, ErrTest = trainMultiLayer(XTrain, DTrain, XTest, DTest ,W0, V0, numIterations, learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot errors\n",
    "# Note: You should not have to modify this code\n",
    "\n",
    "# [minErrTest, minErrTestInd] = min(ErrTest);\n",
    "minErrTest = ErrTest.min()\n",
    "minErrTestInd = ErrTest.argmin()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.semilogy(ErrTrain, 'k', linewidth=1.5, label='Training Error')\n",
    "plt.semilogy(ErrTest, 'r', linewidth=1.5, label='Test Error')\n",
    "plt.semilogy(minErrTestInd, minErrTest, 'bo', linewidth=1.5, label='Min Test Error')\n",
    "\n",
    "plt.xlim([0,numIterations])\n",
    "plt.grid('on')\n",
    "plt.title('Training and Test Errors, Single Layer')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Confusion Matrix and the Accuracy of the data\n",
    "# Note: you have to modify the calcConfusionMatrix() and calcAccuracy() functions in utils.py yourself.\n",
    "\n",
    "_, LPredTrain, _ = runMultiLayer(XTrain, W, V)\n",
    "_, LPredTest , _ = runMultiLayer(XTest , W, V)\n",
    "\n",
    "# The confusion matrix\n",
    "cM = calcConfusionMatrix(LPredTest, LTest)\n",
    "\n",
    "# The accuracy\n",
    "acc = calcAccuracy(cM)\n",
    "\n",
    "# Print the results\n",
    "print(\"Confusion matrix:\")\n",
    "print(cM)\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot classifications\n",
    "# Note: You should not have to modify this code\n",
    "\n",
    "if dataSetNr < 4:\n",
    "    plotResultDots(XTrain, LTrain, LPredTrain, XTest, LTest, LPredTest, 'multi', [W, V], [])\n",
    "else:\n",
    "    plotResultsOCR(XTest, LTest, LPredTest)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd50aace418a96e8a4fe691a4d2292bd7058ca4eeebcf0b6e2084f539c4e7b28"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
