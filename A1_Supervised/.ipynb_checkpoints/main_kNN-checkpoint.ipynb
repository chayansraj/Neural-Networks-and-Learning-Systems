{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **0. Quick introduction to jupyter notebooks**\n",
    "* Each cell in this notebook contains either code or text.\n",
    "* You can run a cell by pressing Ctrl-Enter, or run and advance to the next cell with Shift-Enter.\n",
    "* You can create a cell above the current one by pressing A, or below by pressing B. This only works in command mode (press Esc when editing).\n",
    "* Code cells will print their output, including images, below the cell. Running it again deletes the previous output, so be careful if you want to save some reuslts.\n",
    "* You don't have to rerun all cells to test changes, just rerun the cell you have made changes to. Some exceptions might apply, for example if you overwrite variables from previous cells, but in general this will work.\n",
    "* If all else fails, use the \"Kernel\" menu and select \"Restart Kernel and Clear All Output\". You can also use this menu to run all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This configures the notebook to automatically reload code when it is changed in imported functions.\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "###########################\n",
    "# Import all we need\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils import plotCase, loadDataSet, selectTrainingSamples, calcConfusionMatrix, calcAccuracy, plotResultDots, plotResultsOCR\n",
    "from classifiers import kNN\n",
    "\n",
    "plt.rcParams['figure.facecolor']='white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select which data to use:\n",
    "\n",
    "# 1 = dot cloud 1\n",
    "# 2 = dot cloud 2\n",
    "# 3 = dot cloud 3\n",
    "# 4 = OCR data\n",
    "\n",
    "dataSetNr = 4  # Change this to load new data\n",
    "\n",
    "# X - Data samples\n",
    "# D - Desired output from classifier for each sample\n",
    "# L - Labels for each sample\n",
    "X, D, L = loadDataSet(dataSetNr)\n",
    "\n",
    "# You can plot and study dataset 1 to 3 by running:\n",
    "if dataSetNr in [1,2,3]:\n",
    "    plotCase(X,L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset of the training samples\n",
    "numBins = 2                     # Number of bins you want to divide your data into\n",
    "numSamplesPerLabelPerBin = 100  # Number of samples per label per bin, set to inf for max number (total number is numLabels*numSamplesPerBin)\n",
    "selectAtRandom = True           # true = select samples at random, false = select the first features\n",
    "\n",
    "# Split data into bins based on the settings above.\n",
    "# The outputs are lists of length numBins, where each item is a data array. Try printing for example XBins[0].shape.\n",
    "XBins, DBins, LBins = selectTrainingSamples(X, D, L, numSamplesPerLabelPerBin, numBins, selectAtRandom)\n",
    "\n",
    "# To extract a single bin from them use e.g.:\n",
    "# XBin0 = XBins[0]\n",
    "# Or to combine several bins into one matrix (good for cross validataion), use the numpy function concatenate:\n",
    "# XBinComb = np.concatenate(XBins[0:4])\n",
    "# This example combines 4 bins, nr 0 to 3.\n",
    "\n",
    "# Add your own code to setup data for training and test here\n",
    "rand = int(np.random.randint(0,2,1))\n",
    "XTrain = XBins[rand]\n",
    "LTrain = LBins[rand]\n",
    "XTest  = XBins[1-rand]\n",
    "LTest  = LBins[1-rand]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a value for k, either ...\n",
    "\n",
    "# ... set it manually\n",
    "k = 3\n",
    "\n",
    "# ... or find an optimal value using cross-validation (skip this until you have a working implementation of kNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4760/1496849394.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Classify training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mLPredTrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLTrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# Classify test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mLPredTest\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mkNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXTest\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLTrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\LiU\\Courses\\Neural Networks and Learning Systems - 732A75\\Assignments\\A1_Supervised\\classifiers.py\u001b[0m in \u001b[0;36mkNN\u001b[1;34m(X, k, XTrain, LTrain)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXTrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mXTrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mXTrain\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[0mLPred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mLTrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# Use kNN to classify data\n",
    "# Note: you have to modify the kNN() function in classifiers.py yourself.\n",
    "\n",
    "# Classify training data\n",
    "LPredTrain = kNN(XTrain, k, XTrain, LTrain)\n",
    "# Classify test data\n",
    "LPredTest  = kNN(XTest , k, XTrain, LTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[97  3]\n",
      " [ 1 99]]\n",
      "Accuracy: 98.0000\n"
     ]
    }
   ],
   "source": [
    "# Calculate The Confusion Matrix and the Accuracy\n",
    "# Note: you have to modify the calcConfusionMatrix() and calcAccuracy() functions in utils.py yourself.\n",
    "\n",
    "# The confusion matrix\n",
    "cM = calcConfusionMatrix(LPredTest, LTest)\n",
    "\n",
    "# The accuracy\n",
    "acc = calcAccuracy(cM)\n",
    "\n",
    "# Print the results\n",
    "print(\"Confusion matrix:\")\n",
    "print(cM)\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "cM = calcConfusionMatrix(LPredTrain, LTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = calcAccuracy(cM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[95  5]\n",
      " [ 3 97]]\n",
      "Accuracy: 96.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "print(cM)\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot classifications\n",
    "# Note: You should not have to modify this code\n",
    "\n",
    "if dataSetNr < 4:\n",
    "    plotResultDots(XTrain, LTrain, LPredTrain, XTest, LTest, LPredTest, 'kNN', [], k)\n",
    "else:\n",
    "    plotResultsOCR(XTest, LTest, LPredTest)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd50aace418a96e8a4fe691a4d2292bd7058ca4eeebcf0b6e2084f539c4e7b28"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
